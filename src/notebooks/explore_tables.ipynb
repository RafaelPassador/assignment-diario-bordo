{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a868f0",
   "metadata": {},
   "source": [
    "# Explorando as Tabelas Delta\n",
    "\n",
    "Este notebook permite explorar e manipular as tabelas Delta do projeto de diário de bordo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1252db",
   "metadata": {},
   "source": [
    "## 1. Configuração do SparkSession\n",
    "\n",
    "Configurando a sessão Spark com suporte ao Delta Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3539879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/11 03:28:18 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "SparkSession inicializada com sucesso!\n",
      "Delta Lake configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Configuração do SparkSession com Delta Lake\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"ExplorarTabelas\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/app/spark-warehouse\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dio.delta.sql.DeltaSparkSessionExtension=true\")\n",
    ")\n",
    "\n",
    "spark = builder.getOrCreate()\n",
    "print(\"SparkSession inicializada com sucesso!\")\n",
    "\n",
    "# Verificar se o Delta Lake está disponível\n",
    "try:\n",
    "    spark.sql(\"CREATE TABLE IF NOT EXISTS test_delta USING delta AS SELECT 1 as id\")\n",
    "    spark.sql(\"DROP TABLE test_delta\")\n",
    "    print(\"Delta Lake configurado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao verificar Delta Lake: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c293d",
   "metadata": {},
   "source": [
    "## 2. Carregando a Tabela Bronze\n",
    "\n",
    "Lendo os dados da tabela bronze diretamente do formato Delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c7c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema da tabela Bronze:\n",
      "root\n",
      " |-- DATA_INICIO: string (nullable = true)\n",
      " |-- DATA_FIM: string (nullable = true)\n",
      " |-- CATEGORIA: string (nullable = true)\n",
      " |-- LOCAL_INICIO: string (nullable = true)\n",
      " |-- LOCAL_FIM: string (nullable = true)\n",
      " |-- DISTANCIA: string (nullable = true)\n",
      " |-- PROPOSITO: string (nullable = true)\n",
      "\n",
      "\n",
      "Amostra dos dados:\n",
      "+----------------+----------------+---------+------------+---------------+---------+-----------------+\n",
      "|     DATA_INICIO|        DATA_FIM|CATEGORIA|LOCAL_INICIO|      LOCAL_FIM|DISTANCIA|        PROPOSITO|\n",
      "+----------------+----------------+---------+------------+---------------+---------+-----------------+\n",
      "|01-01-2016 21:11|01-01-2016 21:17|  Negocio| Fort Pierce|    Fort Pierce|       51|      Alimentação|\n",
      "|01-02-2016 01:25|01-02-2016 01:37|  Negocio| Fort Pierce|    Fort Pierce|        5|             null|\n",
      "|01-02-2016 20:25|01-02-2016 20:38|  Negocio| Fort Pierce|    Fort Pierce|       48|         Entregas|\n",
      "|01-05-2016 17:31|01-05-2016 17:45|  Negocio| Fort Pierce|    Fort Pierce|       47|          Reunião|\n",
      "|01-06-2016 14:42|01-06-2016 15:49|  Negocio| Fort Pierce|West Palm Beach|      637|Visita ao cliente|\n",
      "+----------------+----------------+---------+------------+---------------+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando a tabela Bronze e registrando no catálogo\n",
    "bronze_df = spark.read.format(\"delta\").load(\"/app/data/bronze/b_info_transportes\")\n",
    "bronze_df.createOrReplaceTempView(\"b_info_transportes\")\n",
    "print(\"Schema da tabela Bronze:\")\n",
    "bronze_df.printSchema()\n",
    "\n",
    "print(\"\\nAmostra dos dados:\")\n",
    "bronze_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b1a8b",
   "metadata": {},
   "source": [
    "## 3. Carregando a Tabela Silver\n",
    "\n",
    "Lendo os dados da tabela silver processada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb424f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema da tabela Silver:\n",
      "root\n",
      " |-- DATA_INICIO: string (nullable = true)\n",
      " |-- DATA_FIM: string (nullable = true)\n",
      " |-- CATEGORIA: string (nullable = true)\n",
      " |-- LOCAL_INICIO: string (nullable = true)\n",
      " |-- LOCAL_FIM: string (nullable = true)\n",
      " |-- DISTANCIA: string (nullable = true)\n",
      " |-- PROPOSITO: string (nullable = true)\n",
      " |-- DT_REFE: date (nullable = true)\n",
      "\n",
      "\n",
      "Amostra dos dados:\n",
      "+----------------+----------------+---------+----------------+----------+---------+-----------------+----------+\n",
      "|     DATA_INICIO|        DATA_FIM|CATEGORIA|    LOCAL_INICIO| LOCAL_FIM|DISTANCIA|        PROPOSITO|   DT_REFE|\n",
      "+----------------+----------------+---------+----------------+----------+---------+-----------------+----------+\n",
      "|04-01-2016 13:43|04-01-2016 14:01|  negocio|       Kissimmee| Kissimmee|       11|          reunião|2016-01-04|\n",
      "|04-01-2016 14:36|04-01-2016 15:24|  negocio|       Kissimmee|   Orlando|      155|visita ao cliente|2016-01-04|\n",
      "|04-01-2016 16:01|04-01-2016 16:49|  negocio|         Orlando| Kissimmee|      203|          reunião|2016-01-04|\n",
      "|04-01-2016 16:52|04-01-2016 16:57|  pessoal|       Kissimmee| Kissimmee|        7|             null|2016-01-04|\n",
      "|10-11-2016 01:27|10-11-2016 02:08|  negocio|Unknown Location|R?walpindi|      171|          reunião|2016-11-10|\n",
      "+----------------+----------------+---------+----------------+----------+---------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando a tabela Silver e registrando no catálogo\n",
    "silver_df = spark.read.format(\"delta\").load(\"/app/data/silver/s_info_transportes\")\n",
    "silver_df.createOrReplaceTempView(\"s_info_transportes\")\n",
    "print(\"Schema da tabela Silver:\")\n",
    "silver_df.printSchema()\n",
    "\n",
    "print(\"\\nAmostra dos dados:\")\n",
    "silver_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbbea35",
   "metadata": {},
   "source": [
    "## 4. Carregando a Tabela Gold\n",
    "\n",
    "Lendo os dados agregados da tabela gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67fbcab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema da tabela Gold:\n",
      "root\n",
      " |-- DT_REFE: date (nullable = true)\n",
      " |-- QT_CORR: long (nullable = true)\n",
      " |-- QT_CORR_NEG: long (nullable = true)\n",
      " |-- QT_CORR_PESS: long (nullable = true)\n",
      " |-- VL_MAX_DIST: string (nullable = true)\n",
      " |-- VL_MIN_DIST: string (nullable = true)\n",
      " |-- VL_AVG_DIST: double (nullable = true)\n",
      " |-- QT_CORR_REUNI: long (nullable = true)\n",
      " |-- QT_CORR_NAO_REUNI: long (nullable = true)\n",
      "\n",
      "\n",
      "Amostra dos dados:\n",
      "+----------+-------+-----------+------------+-----------+-----------+-----------+-------------+-----------------+\n",
      "|   DT_REFE|QT_CORR|QT_CORR_NEG|QT_CORR_PESS|VL_MAX_DIST|VL_MIN_DIST|VL_AVG_DIST|QT_CORR_REUNI|QT_CORR_NAO_REUNI|\n",
      "+----------+-------+-----------+------------+-----------+-----------+-----------+-------------+-----------------+\n",
      "|2016-06-09|      1|          0|           0|        691|        691|      691.0|            0|                0|\n",
      "|2016-05-05|      3|          0|           0|         29|        129|      100.0|            1|                2|\n",
      "|2016-03-06|      7|          0|           0|         99|        104|       42.0|            2|                5|\n",
      "|2016-10-12|      4|          0|           0|         31|        156|       86.5|            1|                3|\n",
      "|2016-05-07|      5|          0|           0|         99|         12|       60.4|            1|                2|\n",
      "+----------+-------+-----------+------------+-----------+-----------+-----------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregando a tabela Gold e registrando no catálogo\n",
    "gold_df = spark.read.format(\"delta\").load(\"/app/data/gold/info_corridas_do_dia\")\n",
    "gold_df.createOrReplaceTempView(\"info_corridas_do_dia\")\n",
    "print(\"Schema da tabela Gold:\")\n",
    "gold_df.printSchema()\n",
    "\n",
    "print(\"\\nAmostra dos dados:\")\n",
    "gold_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506283a6",
   "metadata": {},
   "source": [
    "## 5. Manipulação dos Dados\n",
    "\n",
    "Exemplos de operações que você pode fazer com os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3d25773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de registros:\n",
      "Bronze: 1,153\n",
      "Silver: 420\n",
      "Gold: 114\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 1: Contagem de registros por tabela\n",
    "print(\"Quantidade de registros:\")\n",
    "print(f\"Bronze: {bronze_df.count():,}\")\n",
    "print(f\"Silver: {silver_df.count():,}\")\n",
    "print(f\"Gold: {gold_df.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed9086b",
   "metadata": {},
   "source": [
    "## Análise das Partições\n",
    "\n",
    "Vamos explorar as partições da tabela Gold por data de referência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 1: Usando os.listdir para ver as partições no sistema de arquivos\n",
    "import os\n",
    "\n",
    "partitions = os.listdir('/app/data/gold/info_corridas_do_dia')\n",
    "partitions = [p for p in partitions if p.startswith('DT_REFE=')]\n",
    "print(f'Total de partições: {len(partitions)}')\n",
    "print('\\nPrimeiras 10 partições:')\n",
    "for p in sorted(partitions)[:10]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 2: Usando Spark SQL para analisar as partições\n",
    "print('\\nAnálise das partições via Spark SQL:')\n",
    "gold_df.select('DT_REFE').distinct().orderBy('DT_REFE').show(10)\n",
    "\n",
    "# Estatísticas por partição\n",
    "print('\\nEstatísticas por partição:')\n",
    "gold_df.groupBy('DT_REFE') \\\n",
    "    .agg({'QTD_CORRIDAS': 'sum'}) \\\n",
    "    .orderBy('DT_REFE') \\\n",
    "    .withColumnRenamed('sum(QTD_CORRIDAS)', 'TOTAL_CORRIDAS') \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 3: Usando SHOW PARTITIONS do Spark SQL\n",
    "print('\\nUsando SHOW PARTITIONS na tabela Gold:')\n",
    "\n",
    "# Agora podemos usar SHOW PARTITIONS na tabela registrada\n",
    "spark.sql(\"SHOW PARTITIONS info_corridas_do_dia\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baa9d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usando spark.table() diretamente:\n",
      "\n",
      "Partições da tabela:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 100:===>                                                   (1 + 14) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   DT_REFE|\n",
      "+----------+\n",
      "|2016-01-01|\n",
      "|2016-01-02|\n",
      "|2016-01-03|\n",
      "|2016-01-04|\n",
      "|2016-01-05|\n",
      "|2016-01-06|\n",
      "|2016-01-07|\n",
      "|2016-01-08|\n",
      "|2016-01-09|\n",
      "|2016-01-11|\n",
      "|2016-01-12|\n",
      "|2016-02-01|\n",
      "|2016-02-02|\n",
      "|2016-02-04|\n",
      "|2016-02-05|\n",
      "|2016-02-07|\n",
      "|2016-02-08|\n",
      "|2016-02-09|\n",
      "|2016-02-11|\n",
      "|2016-02-12|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Método 4: Usando spark.table() na tabela registrada\n",
    "print('\\nUsando spark.table() diretamente:')\n",
    "\n",
    "# Agora podemos usar spark.table() porque a tabela está registrada\n",
    "table_df = spark.table(\"info_corridas_do_dia\")\n",
    "\n",
    "# Mostrando as partições\n",
    "print(\"\\nPartições da tabela:\")\n",
    "table_df.select('DT_REFE').distinct().orderBy('DT_REFE').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01a26cb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'display'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtable_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py:1988\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[1;32m   1991\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'display'"
     ]
    }
   ],
   "source": [
    "table_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5123672",
   "metadata": {},
   "source": [
    "## 6. Consultas Personalizadas\n",
    "\n",
    "Espaço para suas próprias consultas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sua consulta aqui\n",
    "# Exemplo: Filtrar dados por uma condição específica\n",
    "# gold_df.filter(gold_df.QTD_CORRIDAS > 1000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1181ea68",
   "metadata": {},
   "source": [
    "## 7. Visualização dos Dados\n",
    "\n",
    "Diferentes formas de visualizar os dados no PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando show() - forma básica\n",
    "print(\"\\nMétodo 1 - show():\")\n",
    "table_df.show(5)\n",
    "\n",
    "# Usando show() com mais opções\n",
    "print(\"\\nMétodo 2 - show() com mais opções:\")\n",
    "table_df.show(5, truncate=False, vertical=True)\n",
    "\n",
    "# Convertendo para Pandas (útil para visualizações mais elaboradas)\n",
    "print(\"\\nMétodo 3 - Convertendo para Pandas:\")\n",
    "pandas_df = table_df.toPandas()\n",
    "print(pandas_df.head())\n",
    "\n",
    "# Mostrando estatísticas descritivas\n",
    "print(\"\\nMétodo 4 - Estatísticas descritivas:\")\n",
    "table_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando SQL (outra forma de visualizar)\n",
    "print(\"\\nMétodo 5 - Usando SQL:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    DT_REFE,\n",
    "    QTD_CORRIDAS,\n",
    "    TOTAL_PASSAGEIROS\n",
    "FROM info_corridas_do_dia\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
